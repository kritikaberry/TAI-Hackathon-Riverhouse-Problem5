{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  },
  "colab": {
   "provenance": [],
   "toc_visible": true
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "md_title",
   "metadata": {},
   "source": [
    "# ğŸ” AIID Policy & Research Visualizations\n",
    "### AI Incident Database â€” Master Dataset Explorer\n",
    "\n",
    "This notebook produces **3 high-impact visualizations** designed for:\n",
    "- **Policy makers** â€” identifying escalating risk areas and sectors needing regulation\n",
    "- **Researchers** â€” spotting temporal trends, harm patterns, and critical sectors\n",
    "\n",
    "---\n",
    "\n",
    "## ğŸ‘‹ How to use this notebook\n",
    "\n",
    "**3 simple steps:**\n",
    "1. Click **Runtime â†’ Run all** (or press `Ctrl+F9`)\n",
    "2. When prompted in **Cell 3**, click **Choose Files** and upload your `AIID_Master_Dataset.xlsx`\n",
    "3. Wait ~30 seconds â€” all 3 charts will appear automatically\n",
    "\n",
    "**To re-run with a different file:** Click Runtime â†’ Run all again and upload the new file when prompted.\n",
    "\n",
    "---\n",
    "### The 3 Visualizations\n",
    "| # | Chart | Policy Question |\n",
    "|---|-------|-----------------|\n",
    "| 1 | **Risk Domain Escalation Heatmap** | Which AI risk categories are accelerating year-over-year? |\n",
    "| 2 | **Sector Harm Profile** | Which industries face the highest real-world harm exposure? |\n",
    "| 3 | **Incident Surge vs. Harm Timeline** | Is the explosion in incidents translating into more real harm? |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_config",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  âš™ï¸  CELL 1 â€” CONFIGURATION                                                 â•‘\n",
    "# â•‘  This is the only cell you ever need to edit.                               â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â”€â”€ 1A. EXCEL SHEET NAME â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# The name of the sheet containing the master data inside your Excel file.\n",
    "# Default matches the AIID Master Dataset Builder output.\n",
    "SHEET_NAME = \"Master Dataset\"\n",
    "\n",
    "# â”€â”€ 1B. HEADER ROW â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Which row in the Excel sheet contains the column names.\n",
    "# The AIID Master Dataset Builder uses row 3 (rows 1-2 are title/colour bands).\n",
    "# If you're using a plain CSV-style file with headers in row 1, set this to 1.\n",
    "HEADER_ROW = 3\n",
    "\n",
    "# â”€â”€ 1C. COLUMN NAMES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Maps what the notebook expects â†’ the actual column name in your Excel file.\n",
    "# If the Schema Health Check flags a column as missing, update the VALUE here.\n",
    "COLUMN_MAP = {\n",
    "    \"incident_id\"   : \"Incident ID\",\n",
    "    \"year\"          : \"year\",\n",
    "    \"title\"         : \"title\",\n",
    "    \"risk_domain\"   : \"Risk Domain\",\n",
    "    \"risk_subdomain\": \"Risk Subdomain\",\n",
    "    \"intent\"        : \"Intent\",\n",
    "    \"tangible_harm\" : \"Tangible Harm\",\n",
    "    \"sector\"        : \"Sector of Deployment\",\n",
    "    \"lives_lost\"    : \"Lives Lost\",\n",
    "    \"injuries\"      : \"Injuries\",\n",
    "    \"deployer\"      : \"deployer\",\n",
    "    \"data_sources\"  : \"Data Sources\",\n",
    "}\n",
    "\n",
    "# â”€â”€ 1D. VISUALIZATION SETTINGS â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "VIZ_YEAR_START = 2015       # First year to show on charts\n",
    "VIZ_YEAR_END   = 2025       # Last year to show on charts\n",
    "SAVE_CHARTS    = True       # Save PNGs alongside the Excel file\n",
    "CHART_DPI      = 150        # Resolution of saved PNGs\n",
    "\n",
    "# â”€â”€ 1E. SECTOR GROUPING RULES â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Maps keywords found in 'Sector of Deployment' â†’ clean display label.\n",
    "# Add new rows if your data uses different sector names.\n",
    "SECTOR_RULES = [\n",
    "    ([\"transport\"],                          \"Transportation\"),\n",
    "    ([\"health\"],                             \"Healthcare\"),\n",
    "    ([\"law enforce\", \"police\", \"justice\"],   \"Law Enforcement\"),\n",
    "    ([\"education\", \"school\", \"university\"],  \"Education\"),\n",
    "    ([\"financ\", \"bank\", \"insurance\"],        \"Finance & Banking\"),\n",
    "    ([\"retail\", \"wholesale\", \"commerce\"],    \"Retail & Commerce\"),\n",
    "    ([\"admin\", \"public admin\", \"government\"],\"Government & Admin\"),\n",
    "    ([\"information\", \"arts\", \"media\"],       \"Tech & Media\"),\n",
    "    ([\"manufactur\", \"mining\", \"industrial\"], \"Industry & Manufacturing\"),\n",
    "    ([\"agriculture\", \"farming\"],             \"Agriculture\"),\n",
    "    ([\"military\", \"defence\", \"defense\"],     \"Defence\"),\n",
    "]\n",
    "\n",
    "print(\"âœ…  Configuration loaded\")\n",
    "print(f\"    Sheet name    : {SHEET_NAME}\")\n",
    "print(f\"    Header row    : {HEADER_ROW}\")\n",
    "print(f\"    Year range    : {VIZ_YEAR_START} â€“ {VIZ_YEAR_END}\")\n",
    "print(f\"    Save charts   : {SAVE_CHARTS}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_install",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ“¦  CELL 2 â€” INSTALL & IMPORTS  (no editing needed)                        â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "import subprocess, sys\n",
    "for pkg in [\"openpyxl\", \"pandas\", \"matplotlib\", \"seaborn\", \"numpy\"]:\n",
    "    subprocess.run([sys.executable, \"-m\", \"pip\", \"install\", pkg, \"-q\"], check=True)\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import io, os\n",
    "from pathlib import Path\n",
    "from collections import defaultdict\n",
    "\n",
    "import numpy  as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot       as plt\n",
    "import matplotlib.ticker       as mticker\n",
    "import matplotlib.patheffects  as pe\n",
    "from matplotlib.colors       import LinearSegmentedColormap\n",
    "from matplotlib.gridspec     import GridSpec\n",
    "from matplotlib.patches      import Rectangle, FancyArrowPatch\n",
    "\n",
    "# Google Colab helpers\n",
    "try:\n",
    "    from google.colab import files as colab_files\n",
    "    IN_COLAB = True\n",
    "except ImportError:\n",
    "    colab_files = None\n",
    "    IN_COLAB = False\n",
    "\n",
    "# â”€â”€ Global dark theme â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "plt.rcParams.update({\n",
    "    \"figure.facecolor\" : \"#0d1117\",\n",
    "    \"axes.facecolor\"   : \"#161b22\",\n",
    "    \"axes.edgecolor\"   : \"#30363d\",\n",
    "    \"axes.labelcolor\"  : \"#c9d1d9\",\n",
    "    \"axes.titlecolor\"  : \"#e6edf3\",\n",
    "    \"axes.titlesize\"   : 13,\n",
    "    \"axes.titleweight\" : \"bold\",\n",
    "    \"axes.labelsize\"   : 10,\n",
    "    \"xtick.color\"      : \"#8b949e\",\n",
    "    \"ytick.color\"      : \"#8b949e\",\n",
    "    \"xtick.labelsize\"  : 8.5,\n",
    "    \"ytick.labelsize\"  : 8.5,\n",
    "    \"grid.color\"       : \"#21262d\",\n",
    "    \"grid.linewidth\"   : 0.6,\n",
    "    \"text.color\"       : \"#c9d1d9\",\n",
    "    \"font.family\"      : \"monospace\",\n",
    "    \"legend.facecolor\" : \"#161b22\",\n",
    "    \"legend.edgecolor\" : \"#30363d\",\n",
    "    \"legend.fontsize\"  : 8.5,\n",
    "})\n",
    "\n",
    "ACCENT  = \"#58a6ff\"\n",
    "DANGER  = \"#f85149\"\n",
    "WARN    = \"#e3b341\"\n",
    "SUCCESS = \"#3fb950\"\n",
    "PURPLE  = \"#bc8cff\"\n",
    "\n",
    "print(f\"âœ…  Libraries ready  |  Running in {'Google Colab' if IN_COLAB else 'local Jupyter'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_upload",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ“  CELL 3 â€” UPLOAD YOUR FILE  (no editing needed)                         â•‘\n",
    "# â•‘                                                                              â•‘\n",
    "# â•‘  In Google Colab: a file picker will appear â€” click \"Choose Files\" and      â•‘\n",
    "# â•‘  select your AIID_Master_Dataset.xlsx file.                                 â•‘\n",
    "# â•‘                                                                              â•‘\n",
    "# â•‘  Running locally: place your Excel file in the same folder as this          â•‘\n",
    "# â•‘  notebook and set LOCAL_FILEPATH below.                                     â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â”€â”€ For local Jupyter only: set the path to your Excel file here â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "LOCAL_FILEPATH = \"AIID_Master_Dataset.xlsx\"   # â† change this if running locally\n",
    "\n",
    "UPLOADED_PATH = None\n",
    "\n",
    "if IN_COLAB:\n",
    "    print(\"ğŸ“‚  Please select your AIID Master Dataset Excel file...\")\n",
    "    print(\"    (Click the 'Choose Files' button that appears below)\")\n",
    "    print()\n",
    "    uploaded = colab_files.upload()\n",
    "\n",
    "    if not uploaded:\n",
    "        raise ValueError(\n",
    "            \"No file was uploaded. Please re-run this cell and select your Excel file.\"\n",
    "        )\n",
    "\n",
    "    filename = list(uploaded.keys())[0]\n",
    "    if not filename.endswith((\".xlsx\", \".xls\")):\n",
    "        raise ValueError(\n",
    "            f\"Uploaded file '{filename}' does not appear to be an Excel file (.xlsx/.xls). \"\n",
    "            \"Please upload the correct file.\"\n",
    "        )\n",
    "\n",
    "    UPLOADED_PATH = f\"/content/{filename}\"\n",
    "    print(f\"\\nâœ…  File uploaded : {filename}\")\n",
    "    print(f\"    Size          : {len(uploaded[filename]) / 1024:.1f} KB\")\n",
    "\n",
    "else:\n",
    "    # Local mode â€” check file exists\n",
    "    p = Path(LOCAL_FILEPATH)\n",
    "    if not p.exists():\n",
    "        raise FileNotFoundError(\n",
    "            f\"File not found: {p.resolve()}\\n\"\n",
    "            f\"Please place your Excel file at that path, or update LOCAL_FILEPATH above.\"\n",
    "        )\n",
    "    UPLOADED_PATH = str(p)\n",
    "    print(f\"âœ…  File found    : {p.resolve()}\")\n",
    "    print(f\"    Size          : {p.stat().st_size / 1024:.1f} KB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_schema_check",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ”  CELL 4 â€” SCHEMA HEALTH CHECK  (no editing needed)                      â•‘\n",
    "# â•‘  Checks that all expected columns exist before loading data.                â•‘\n",
    "# â•‘  If a column is flagged MISSING, update COLUMN_MAP in Cell 1.               â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "SEP = \"â”€\" * 60\n",
    "\n",
    "# â”€â”€ Read only headers from the file (fast) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "try:\n",
    "    _preview = pd.read_excel(\n",
    "        UPLOADED_PATH,\n",
    "        sheet_name = SHEET_NAME,\n",
    "        header     = HEADER_ROW - 1,  # pandas is 0-indexed\n",
    "        nrows      = 0\n",
    "    )\n",
    "    actual_cols = set(_preview.columns.astype(str))\n",
    "except Exception as e:\n",
    "    # Provide a clear error if sheet name is wrong\n",
    "    import openpyxl as _opx\n",
    "    _wb = _opx.load_workbook(UPLOADED_PATH, read_only=True)\n",
    "    available_sheets = _wb.sheetnames\n",
    "    raise ValueError(\n",
    "        f\"Could not find sheet '{SHEET_NAME}' in the uploaded file.\\n\"\n",
    "        f\"Sheets available: {available_sheets}\\n\"\n",
    "        f\"Update SHEET_NAME in Cell 1 to match one of the above.\"\n",
    "    ) from e\n",
    "\n",
    "# â”€â”€ Compare COLUMN_MAP against actual columns â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "print(SEP)\n",
    "print(\"  ğŸ”  SCHEMA HEALTH CHECK\")\n",
    "print(SEP)\n",
    "print(f\"  Sheet  : '{SHEET_NAME}'\")\n",
    "print(f\"  Columns found in file: {len(actual_cols)}\")\n",
    "print()\n",
    "\n",
    "all_ok  = True\n",
    "missing = []\n",
    "\n",
    "for key, col_name in COLUMN_MAP.items():\n",
    "    found = col_name in actual_cols\n",
    "    status = \"âœ…\" if found else \"âŒ\"\n",
    "    if not found:\n",
    "        all_ok = False\n",
    "        missing.append((key, col_name))\n",
    "        # Suggest close matches\n",
    "        close = [\n",
    "            c for c in actual_cols\n",
    "            if col_name.lower().replace(\" \",\"\") in c.lower().replace(\" \",\"\")\n",
    "            or c.lower().replace(\" \",\"\") in col_name.lower().replace(\" \",\"\")\n",
    "        ]\n",
    "        hint = f\"  â†’ Did you mean: {close[:3]}?\" if close else \"\"\n",
    "        print(f\"  {status}  '{col_name}'{hint}\")\n",
    "    else:\n",
    "        print(f\"  {status}  '{col_name}'\")\n",
    "\n",
    "print()\n",
    "print(SEP)\n",
    "if all_ok:\n",
    "    print(\"  âœ…  All columns found â€” safe to load data\")\n",
    "else:\n",
    "    print(f\"  âŒ  {len(missing)} column(s) not found\")\n",
    "    print()\n",
    "    print(\"  HOW TO FIX:\")\n",
    "    print(\"  1. Go back to Cell 1 (âš™ï¸ Configuration)\")\n",
    "    print(\"  2. In COLUMN_MAP, find the entry for the missing column\")\n",
    "    print(\"  3. Update the VALUE to match the exact column name shown above\")\n",
    "    print(\"  4. Re-run from Cell 1\")\n",
    "print(SEP)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_load",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ“‚  CELL 5 â€” LOAD DATA  (no editing needed)                                â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "print(\"Loading data ... \", end=\"\", flush=True)\n",
    "\n",
    "df_raw = pd.read_excel(\n",
    "    UPLOADED_PATH,\n",
    "    sheet_name = SHEET_NAME,\n",
    "    header     = HEADER_ROW - 1,\n",
    "    dtype      = str               # read everything as strings first â€” safe for mixed types\n",
    ")\n",
    "\n",
    "# Rename to internal keys using COLUMN_MAP (only rename columns that exist)\n",
    "rename_map = {v: k for k, v in COLUMN_MAP.items() if v in df_raw.columns}\n",
    "df = df_raw.rename(columns=rename_map).copy()\n",
    "\n",
    "# Drop rows with no Incident ID (blank rows from Excel formatting)\n",
    "df = df[df[\"incident_id\"].notna() & (df[\"incident_id\"].str.strip() != \"\")].copy()\n",
    "\n",
    "# Parse year to int\n",
    "df[\"year\"] = pd.to_numeric(df[\"year\"], errors=\"coerce\").astype(\"Int64\")\n",
    "\n",
    "# Parse numeric columns\n",
    "for col in [\"lives_lost\", \"injuries\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\").fillna(0)\n",
    "\n",
    "# Normalise text columns (strip whitespace)\n",
    "for col in [\"risk_domain\", \"risk_subdomain\", \"intent\", \"tangible_harm\", \"sector\"]:\n",
    "    if col in df.columns:\n",
    "        df[col] = df[col].astype(str).str.strip().replace(\"nan\", \"\")\n",
    "\n",
    "print(f\"done\")\n",
    "\n",
    "# â”€â”€ Summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "total_rows  = len(df)\n",
    "year_min    = int(df[\"year\"].dropna().min())\n",
    "year_max    = int(df[\"year\"].dropna().max())\n",
    "total_cols  = len(df.columns)\n",
    "\n",
    "mit_pct  = (df[\"risk_domain\"].replace(\"\", pd.NA).notna().mean() * 100) if \"risk_domain\" in df.columns else 0\n",
    "harm_pct = (df[\"tangible_harm\"].replace(\"\", pd.NA).notna().mean() * 100) if \"tangible_harm\" in df.columns else 0\n",
    "sec_pct  = (df[\"sector\"].replace(\"\", pd.NA).notna().mean() * 100) if \"sector\" in df.columns else 0\n",
    "\n",
    "SEP = \"â•\" * 52\n",
    "print(f\"\\n{SEP}\")\n",
    "print(f\"  DATASET LOADED SUCCESSFULLY\")\n",
    "print(SEP)\n",
    "print(f\"  Total incidents        : {total_rows:>7,}\")\n",
    "print(f\"  Date range             : {year_min} â†’ {year_max}\")\n",
    "print(f\"  Columns                : {total_cols}\")\n",
    "print()\n",
    "print(f\"  Column coverage:\")\n",
    "print(f\"    Risk Domain (MIT)    : {mit_pct:>5.1f}%\")\n",
    "print(f\"    Tangible Harm (CSET) : {harm_pct:>5.1f}%\")\n",
    "print(f\"    Sector (CSET)        : {sec_pct:>5.1f}%\")\n",
    "\n",
    "# â”€â”€ Auto-detect Risk Domains from data (replaces hardcoded list) â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "YEARS = list(range(VIZ_YEAR_START, VIZ_YEAR_END + 1))\n",
    "\n",
    "if \"risk_domain\" in df.columns:\n",
    "    DOMAINS = (\n",
    "        df[df[\"year\"].isin(YEARS)][\"risk_domain\"]\n",
    "        .replace(\"\", pd.NA).dropna()\n",
    "        .value_counts()\n",
    "        .index.tolist()\n",
    "    )\n",
    "    print(f\"\\n  Risk Domains detected  : {len(DOMAINS)}\")\n",
    "    for d in DOMAINS:\n",
    "        print(f\"    â€¢ {d}\")\n",
    "else:\n",
    "    DOMAINS = []\n",
    "\n",
    "print(SEP)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_viz1",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š Visualization 1 â€” Risk Domain Escalation Heatmap\n",
    "**Policy Question:** *Which AI risk categories are accelerating, and where should regulatory attention focus?*\n",
    "\n",
    "Each cell shows the **raw incident count** for that risk category in that year.  \n",
    "Colour intensity is **log-normalized per row** so both slow-burn and fast-escalating risks are visible side-by-side.  \n",
    "The âš  Surge Zone highlights the most recent years where growth is sharpest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_viz1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ“Š  CELL 6 â€” VISUALIZATION 1: Risk Domain Escalation Heatmap               â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if not DOMAINS:\n",
    "    print(\"âš ï¸  No Risk Domain data found in the dataset. Skipping Visualization 1.\")\n",
    "    print(\"   Check that 'risk_domain' is mapped correctly in Cell 1 (COLUMN_MAP).\")\n",
    "else:\n",
    "    # â”€â”€ Build domain Ã— year matrix â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    matrix = np.zeros((len(DOMAINS), len(YEARS)), dtype=int)\n",
    "    viz1_df = df[df[\"year\"].isin(YEARS) & df[\"risk_domain\"].ne(\"\")]\n",
    "\n",
    "    for _, row in viz1_df.iterrows():\n",
    "        yr  = row[\"year\"]\n",
    "        dom = row[\"risk_domain\"]\n",
    "        if yr in YEARS and dom in DOMAINS:\n",
    "            matrix[DOMAINS.index(dom)][YEARS.index(yr)] += 1\n",
    "\n",
    "    # Row-wise log-normalize for colour intensity\n",
    "    matrix_norm = np.zeros_like(matrix, dtype=float)\n",
    "    for i, row in enumerate(matrix):\n",
    "        m = row.max()\n",
    "        if m > 0:\n",
    "            matrix_norm[i] = np.log1p(row) / np.log1p(m)\n",
    "\n",
    "    # â”€â”€ Dynamic insight computation â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    # Find the domain with the highest growth in the last 3 years vs prior 3 years\n",
    "    insights = []\n",
    "    last_3_idx  = [YEARS.index(y) for y in YEARS[-3:]  if y in YEARS]\n",
    "    prior_3_idx = [YEARS.index(y) for y in YEARS[-6:-3] if y in YEARS]\n",
    "\n",
    "    for i, dom in enumerate(DOMAINS):\n",
    "        recent = matrix[i][last_3_idx].sum()  if last_3_idx  else 0\n",
    "        prior  = matrix[i][prior_3_idx].sum() if prior_3_idx else 0\n",
    "        if prior > 0:\n",
    "            growth_pct = (recent - prior) / prior * 100\n",
    "        elif recent > 0:\n",
    "            growth_pct = 999\n",
    "        else:\n",
    "            growth_pct = 0\n",
    "        insights.append((dom, recent, prior, growth_pct))\n",
    "\n",
    "    insights.sort(key=lambda x: x[3], reverse=True)\n",
    "    domain_totals = matrix.sum(axis=1)\n",
    "\n",
    "    # â”€â”€ Wrap long domain labels â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def wrap_label(label, max_len=22):\n",
    "        if len(label) <= max_len:\n",
    "            return label\n",
    "        parts = label.split(\" \")\n",
    "        mid = len(parts) // 2\n",
    "        return \" \".join(parts[:mid]) + \"\\n\" + \" \".join(parts[mid:])\n",
    "\n",
    "    domain_labels = [wrap_label(d) for d in DOMAINS]\n",
    "\n",
    "    # â”€â”€ Plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    cmap = LinearSegmentedColormap.from_list(\n",
    "        \"aiid\", [\"#0d1117\", \"#1f4068\", \"#1b6ca8\", \"#e3b341\", \"#f85149\"], N=256\n",
    "    )\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(16, max(5, len(DOMAINS) * 0.85 + 1.5)))\n",
    "    fig.patch.set_facecolor(\"#0d1117\")\n",
    "    ax.set_facecolor(\"#0d1117\")\n",
    "\n",
    "    im = ax.imshow(matrix_norm, cmap=cmap, aspect=\"auto\", vmin=0, vmax=1)\n",
    "\n",
    "    for i in range(len(DOMAINS)):\n",
    "        for j in range(len(YEARS)):\n",
    "            val  = matrix[i][j]\n",
    "            norm = matrix_norm[i][j]\n",
    "            col  = \"white\" if norm > 0.4 else \"#8b949e\"\n",
    "            fw   = \"bold\"  if norm > 0.65 else \"normal\"\n",
    "            ax.text(j, i, str(val), ha=\"center\", va=\"center\",\n",
    "                    fontsize=8.5, color=col, fontweight=fw, fontfamily=\"monospace\")\n",
    "\n",
    "    ax.set_xticks(range(len(YEARS)))\n",
    "    ax.set_xticklabels(YEARS, fontsize=9)\n",
    "    ax.set_yticks(range(len(domain_labels)))\n",
    "    ax.set_yticklabels(domain_labels, fontsize=9)\n",
    "\n",
    "    ax.set_title(\n",
    "        f\"Risk Domain Escalation Heatmap  Â·  Incident Count by Category & Year ({VIZ_YEAR_START}â€“{VIZ_YEAR_END})\\n\"\n",
    "        \"Colour intensity = log-normalized within each row  |  Numbers = raw counts\",\n",
    "        pad=14, fontsize=12, color=\"#e6edf3\"\n",
    "    )\n",
    "\n",
    "    cb = fig.colorbar(im, ax=ax, fraction=0.015, pad=0.02)\n",
    "    cb.set_label(\"Normalized Intensity (per domain peak)\", color=\"#8b949e\", fontsize=8)\n",
    "    cb.ax.yaxis.set_tick_params(color=\"#8b949e\")\n",
    "    cb.outline.set_edgecolor(\"#30363d\")\n",
    "    plt.setp(cb.ax.yaxis.get_ticklabels(), color=\"#8b949e\")\n",
    "\n",
    "    # Right-side totals\n",
    "    ax2 = ax.twinx()\n",
    "    ax2.set_ylim(-0.5, len(DOMAINS) - 0.5)\n",
    "    ax2.set_yticks(range(len(DOMAINS)))\n",
    "    ax2.set_yticklabels([f\"  Î£ {t:,}\" for t in domain_totals], fontsize=8, color=ACCENT)\n",
    "    ax2.tick_params(length=0)\n",
    "    ax2.spines[:].set_visible(False)\n",
    "\n",
    "    # Surge zone box â€” last 3 years\n",
    "    surge_start = len(YEARS) - 3 - 0.5\n",
    "    rect = Rectangle((surge_start, -0.5), 3, len(DOMAINS),\n",
    "                      linewidth=1.5, edgecolor=WARN, facecolor=\"none\",\n",
    "                      linestyle=\"--\", alpha=0.6)\n",
    "    ax.add_patch(rect)\n",
    "    ax.text(surge_start + 1.5, -0.85, \"âš  Surge Zone\",\n",
    "            ha=\"center\", fontsize=8, color=WARN, fontfamily=\"monospace\")\n",
    "\n",
    "    ax.spines[:].set_edgecolor(\"#30363d\")\n",
    "    plt.tight_layout()\n",
    "\n",
    "    if SAVE_CHARTS:\n",
    "        out_path = str(Path(UPLOADED_PATH).parent / \"viz1_risk_heatmap.png\")\n",
    "        plt.savefig(out_path, dpi=CHART_DPI, bbox_inches=\"tight\",\n",
    "                    facecolor=\"#0d1117\", edgecolor=\"none\")\n",
    "        print(f\"ğŸ’¾  Saved: {out_path}\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "    # â”€â”€ Dynamic insights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    print(\"\\nğŸ“Œ  KEY INSIGHTS â€” computed from your data\")\n",
    "    print(f\"    Total incidents {VIZ_YEAR_START}â€“{VIZ_YEAR_END}: {matrix.sum():,}\")\n",
    "    print(f\"    Fastest-growing risk domains (last 3 years vs prior 3 years):\")\n",
    "    for dom, recent, prior, pct in insights[:3]:\n",
    "        if pct == 999:\n",
    "            print(f\"      â€¢ {dom:<45}  New category â€” {recent} incidents\")\n",
    "        else:\n",
    "            direction = \"â–²\" if pct > 0 else \"â–¼\"\n",
    "            print(f\"      â€¢ {dom:<45}  {direction} {abs(pct):+.0f}%  ({prior} â†’ {recent} incidents)\")\n",
    "    print(f\"    Largest domain by total volume: {DOMAINS[domain_totals.argmax()]} ({domain_totals.max():,} incidents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_viz2",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š Visualization 2 â€” Sector Harm Profile\n",
    "**Policy Question:** *Which sectors are most exposed to real, tangible AI-caused harm â€” and should be prioritized for sector-specific AI regulation?*\n",
    "\n",
    "This stacked horizontal bar chart shows **harm severity** (Confirmed â†’ No Harm) broken down by **industry sector**.  \n",
    "The **Harm Risk Score** (weighted composite: ConfirmedÃ—4 + Near MissÃ—2 + IssueÃ—1) ranks sectors by regulatory urgency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_viz2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ“Š  CELL 7 â€” VISUALIZATION 2: Sector Harm Profile                          â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "if \"sector\" not in df.columns or \"tangible_harm\" not in df.columns:\n",
    "    print(\"âš ï¸  Sector or Tangible Harm column not found. Skipping Visualization 2.\")\n",
    "    print(\"   Check COLUMN_MAP in Cell 1.\")\n",
    "else:\n",
    "    # â”€â”€ Apply sector grouping rules from Cell 1 config â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "    def classify_sector(raw):\n",
    "        if not raw or raw == \"nan\":\n",
    "            return None\n",
    "        s = str(raw).lower()\n",
    "        for keywords, label in SECTOR_RULES:\n",
    "            if any(kw in s for kw in keywords):\n",
    "                return label\n",
    "        return None\n",
    "\n",
    "    HARM_CATS  = [\"Confirmed Harm\", \"Near Miss\", \"Risk Issue\", \"No Harm / Unclear\"]\n",
    "    HARM_SCORE = {\"Confirmed Harm\": 4, \"Near Miss\": 2, \"Risk Issue\": 1, \"No Harm / Unclear\": 0}\n",
    "\n",
    "    def classify_harm(raw):\n",
    "        s = str(raw or \"\").lower()\n",
    "        if \"definitively\" in s: return \"Confirmed Harm\"\n",
    "        if \"near miss\"    in s: return \"Near Miss\"\n",
    "        if \"issue\"        in s: return \"Risk Issue\"\n",
    "        return \"No Harm / Unclear\"\n",
    "\n",
    "    sector_counts = defaultdict(lambda: defaultdict(int))\n",
    "    for _, row in df.iterrows():\n",
    "        sec  = classify_sector(row.get(\"sector\"))\n",
    "        if not sec:\n",
    "            continue\n",
    "        harm = classify_harm(row.get(\"tangible_harm\"))\n",
    "        sector_counts[sec][harm] += 1\n",
    "\n",
    "    if not sector_counts:\n",
    "        print(\"âš ï¸  No sector data could be classified. Check your SECTOR_RULES in Cell 1.\")\n",
    "    else:\n",
    "        # Sort by Harm Risk Score ascending (highest ends up at top of horiz chart)\n",
    "        sectors = sorted(\n",
    "            sector_counts.keys(),\n",
    "            key=lambda s: sum(sector_counts[s][c] * HARM_SCORE[c] for c in HARM_CATS)\n",
    "        )\n",
    "        scores     = [sum(sector_counts[s][c] * HARM_SCORE[c] for c in HARM_CATS) for s in sectors]\n",
    "        totals_sec = [sum(sector_counts[s][c] for c in HARM_CATS) for s in sectors]\n",
    "\n",
    "        BAR_COLORS = {\n",
    "            \"Confirmed Harm\"    : DANGER,\n",
    "            \"Near Miss\"         : WARN,\n",
    "            \"Risk Issue\"        : ACCENT,\n",
    "            \"No Harm / Unclear\" : \"#484f58\",\n",
    "        }\n",
    "\n",
    "        fig, (ax_main, ax_score) = plt.subplots(\n",
    "            1, 2, figsize=(16, max(5, len(sectors) * 0.7 + 2)),\n",
    "            gridspec_kw={\"width_ratios\": [3.2, 1]}\n",
    "        )\n",
    "        fig.patch.set_facecolor(\"#0d1117\")\n",
    "\n",
    "        lefts = np.zeros(len(sectors))\n",
    "        for cat in HARM_CATS:\n",
    "            vals = [sector_counts[s][cat] for s in sectors]\n",
    "            bars = ax_main.barh(sectors, vals, left=lefts,\n",
    "                                color=BAR_COLORS[cat], label=cat,\n",
    "                                height=0.62, alpha=0.92)\n",
    "            for bar, v in zip(bars, vals):\n",
    "                if v >= 2:\n",
    "                    x = bar.get_x() + bar.get_width() / 2\n",
    "                    y = bar.get_y() + bar.get_height() / 2\n",
    "                    ax_main.text(x, y, str(v), ha=\"center\", va=\"center\",\n",
    "                                 fontsize=8, color=\"white\",\n",
    "                                 fontfamily=\"monospace\", fontweight=\"bold\")\n",
    "            lefts += vals\n",
    "\n",
    "        for i, (s, tot) in enumerate(zip(sectors, totals_sec)):\n",
    "            ax_main.text(lefts[i] + 0.4, i, f\" {tot}\", va=\"center\",\n",
    "                         fontsize=8.5, color=\"#8b949e\", fontfamily=\"monospace\")\n",
    "\n",
    "        ax_main.set_facecolor(\"#161b22\")\n",
    "        ax_main.spines[:].set_edgecolor(\"#30363d\")\n",
    "        ax_main.set_xlabel(\"Number of Incidents\", labelpad=8)\n",
    "        ax_main.set_title(\n",
    "            \"Sector Harm Profile  Â·  Incident Severity by Industry\\n\"\n",
    "            \"Sorted by Harm Risk Score  (ConfirmedÃ—4 + Near MissÃ—2 + IssueÃ—1)\",\n",
    "            fontsize=12, pad=12\n",
    "        )\n",
    "        ax_main.legend(loc=\"lower right\", framealpha=0.9)\n",
    "        ax_main.grid(axis=\"x\", alpha=0.3)\n",
    "        ax_main.set_axisbelow(True)\n",
    "\n",
    "        score_colors = [\n",
    "            DANGER if sc >= 50 else WARN if sc >= 20 else ACCENT\n",
    "            for sc in scores\n",
    "        ]\n",
    "        bars_s = ax_score.barh(sectors, scores, color=score_colors, height=0.62, alpha=0.88)\n",
    "        for bar, sc in zip(bars_s, scores):\n",
    "            ax_score.text(\n",
    "                bar.get_width() + 0.5, bar.get_y() + bar.get_height() / 2,\n",
    "                f\"{sc:.0f}\", va=\"center\", fontsize=8.5, color=\"#c9d1d9\",\n",
    "                fontfamily=\"monospace\", fontweight=\"bold\"\n",
    "            )\n",
    "\n",
    "        ax_score.set_facecolor(\"#161b22\")\n",
    "        ax_score.spines[:].set_edgecolor(\"#30363d\")\n",
    "        ax_score.set_xlabel(\"Harm Risk Score\", labelpad=8)\n",
    "        ax_score.set_title(\"Risk\\nScore\", fontsize=10, pad=12)\n",
    "        ax_score.set_yticks([])\n",
    "        ax_score.grid(axis=\"x\", alpha=0.3)\n",
    "        ax_score.set_axisbelow(True)\n",
    "\n",
    "        if max(scores) > 0:\n",
    "            high_urgency = max(scores) * 0.6\n",
    "            ax_score.axvline(high_urgency, color=DANGER, linestyle=\"--\", alpha=0.5, linewidth=1)\n",
    "            ax_score.text(high_urgency + 0.5, -0.6, \"High\\nUrgency\",\n",
    "                          color=DANGER, fontsize=7, va=\"bottom\")\n",
    "\n",
    "        plt.tight_layout()\n",
    "\n",
    "        if SAVE_CHARTS:\n",
    "            out_path = str(Path(UPLOADED_PATH).parent / \"viz2_sector_harm.png\")\n",
    "            plt.savefig(out_path, dpi=CHART_DPI, bbox_inches=\"tight\",\n",
    "                        facecolor=\"#0d1117\", edgecolor=\"none\")\n",
    "            print(f\"ğŸ’¾  Saved: {out_path}\")\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        # â”€â”€ Dynamic insights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "        sorted_by_score = sorted(zip(sectors, scores), key=lambda x: x[1], reverse=True)\n",
    "        print(\"\\nğŸ“Œ  KEY INSIGHTS â€” computed from your data\")\n",
    "        print(f\"    Sectors analysed: {len(sectors)}\")\n",
    "        print(f\"    Top sectors by Harm Risk Score:\")\n",
    "        for rank, (sec, score) in enumerate(sorted_by_score[:5], 1):\n",
    "            confirmed = sector_counts[sec][\"Confirmed Harm\"]\n",
    "            total_s   = sum(sector_counts[sec][c] for c in HARM_CATS)\n",
    "            pct       = confirmed / total_s * 100 if total_s > 0 else 0\n",
    "            print(f\"      #{rank}  {sec:<30}  Score: {score:>4.0f}  |  \"\n",
    "                  f\"Confirmed harm: {confirmed} ({pct:.0f}% of sector incidents)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_viz3",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“Š Visualization 3 â€” Incident Surge vs. Harm Severity Over Time\n",
    "**Policy Question:** *Is the explosive growth in AI incidents translating into more real-world harm â€” or are safeguards keeping pace?*\n",
    "\n",
    "This dual-axis chart overlays:\n",
    "- **Total incident volume** (bars) split by Intentional vs Unintentional  \n",
    "- **Confirmed harm rate** (%) as a dashed line â€” showing whether harm keeps pace with incident growth  \n",
    "- **Injury counts** as a secondary panel â€” the physical impact signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_viz3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ“Š  CELL 8 â€” VISUALIZATION 3: Incident Surge vs. Harm Timeline             â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "# â”€â”€ Build year-level summary â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "year_stats = {\n",
    "    y: {\"total\": 0, \"intentional\": 0, \"unintentional\": 0,\n",
    "        \"harm_events\": 0, \"near_miss\": 0, \"lives\": 0.0, \"injuries\": 0.0}\n",
    "    for y in YEARS\n",
    "}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    yr = row.get(\"year\")\n",
    "    if pd.isna(yr) or int(yr) not in YEARS:\n",
    "        continue\n",
    "    st = year_stats[int(yr)]\n",
    "    st[\"total\"] += 1\n",
    "    intent = str(row.get(\"intent\") or \"\").lower()\n",
    "    if   \"intentional\"   == intent: st[\"intentional\"]   += 1\n",
    "    elif \"unintentional\" == intent: st[\"unintentional\"] += 1\n",
    "    harm = str(row.get(\"tangible_harm\") or \"\").lower()\n",
    "    if \"definitively\" in harm: st[\"harm_events\"] += 1\n",
    "    if \"near miss\"    in harm: st[\"near_miss\"]   += 1\n",
    "    st[\"injuries\"] += float(row.get(\"injuries\") or 0)\n",
    "    st[\"lives\"]    += float(row.get(\"lives_lost\") or 0)\n",
    "\n",
    "totals_v3  = [year_stats[y][\"total\"]         for y in YEARS]\n",
    "intents_v3 = [year_stats[y][\"intentional\"]   for y in YEARS]\n",
    "uninten_v3 = [year_stats[y][\"unintentional\"] for y in YEARS]\n",
    "harms_v3   = [year_stats[y][\"harm_events\"]   for y in YEARS]\n",
    "inj_raw    = [year_stats[y][\"injuries\"]       for y in YEARS]\n",
    "inj_cap    = 1500  # cap for display scale\n",
    "injuries_v3 = [min(v, inj_cap) for v in inj_raw]\n",
    "harm_rate  = [h / t * 100 if t > 0 else 0 for h, t in zip(harms_v3, totals_v3)]\n",
    "\n",
    "# â”€â”€ Plot â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "fig = plt.figure(figsize=(16, 8), facecolor=\"#0d1117\")\n",
    "gs  = GridSpec(3, 1, height_ratios=[3, 1, 0.08], hspace=0.08)\n",
    "ax_main = fig.add_subplot(gs[0])\n",
    "ax_inj  = fig.add_subplot(gs[1], sharex=ax_main)\n",
    "ax_gap  = fig.add_subplot(gs[2])\n",
    "ax_gap.axis(\"off\")\n",
    "\n",
    "x = np.arange(len(YEARS))\n",
    "w = 0.65\n",
    "\n",
    "# Stacked bars\n",
    "ax_main.bar(x, uninten_v3, width=w, label=\"Unintentional\",\n",
    "            color=\"#1f4068\", alpha=0.9, zorder=2)\n",
    "ax_main.bar(x, intents_v3, width=w, bottom=uninten_v3,\n",
    "            label=\"Intentional\", color=DANGER, alpha=0.85, zorder=2)\n",
    "\n",
    "# Harm event bubbles\n",
    "y_bubbles = [u + i + max(totals_v3) * 0.04 for u, i in zip(uninten_v3, intents_v3)]\n",
    "ax_main.scatter(x, y_bubbles,\n",
    "                s=[h * 18 + 10 for h in harms_v3],\n",
    "                color=WARN, alpha=0.85, zorder=3,\n",
    "                label=\"Confirmed Harm (bubble size)\",\n",
    "                edgecolors=\"white\", linewidths=0.5)\n",
    "\n",
    "# Harm rate line (twin axis)\n",
    "ax_r = ax_main.twinx()\n",
    "ax_r.set_facecolor(\"none\")\n",
    "ax_r.plot(x, harm_rate, color=WARN, linewidth=2, linestyle=\"--\",\n",
    "          marker=\"o\", markersize=5, zorder=4, label=\"Harm Rate %\")\n",
    "ax_r.fill_between(x, harm_rate, alpha=0.08, color=WARN)\n",
    "ax_r.set_ylabel(\"Confirmed Harm Rate (%)\", color=WARN, fontsize=9)\n",
    "ax_r.tick_params(axis=\"y\", colors=WARN, labelsize=8)\n",
    "ax_r.spines[:].set_edgecolor(\"#30363d\")\n",
    "if max(harm_rate) > 0:\n",
    "    ax_r.set_ylim(0, max(harm_rate) * 2.2)\n",
    "ax_r.yaxis.set_major_formatter(mticker.FormatStrFormatter(\"%.0f%%\"))\n",
    "\n",
    "# Total labels on bars\n",
    "for xi, tot in enumerate(totals_v3):\n",
    "    if tot > 0:\n",
    "        ax_main.text(xi, tot + max(totals_v3) * 0.015, str(tot),\n",
    "                     ha=\"center\", fontsize=7.5, color=\"#c9d1d9\",\n",
    "                     fontfamily=\"monospace\", fontweight=\"bold\")\n",
    "\n",
    "# â”€â”€ Annotate significant real-world events dynamically â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "# Find the 2 years with the biggest YoY jumps and annotate them\n",
    "yoy_jumps = [(YEARS[i], totals_v3[i] - totals_v3[i-1])\n",
    "             for i in range(1, len(YEARS)) if totals_v3[i-1] > 0]\n",
    "top_jumps = sorted(yoy_jumps, key=lambda x: x[1], reverse=True)[:2]\n",
    "\n",
    "for yr, jump in top_jumps:\n",
    "    xi  = YEARS.index(yr)\n",
    "    pct = jump / totals_v3[xi-1] * 100 if totals_v3[xi-1] > 0 else 0\n",
    "    ax_main.annotate(\n",
    "        f\"+{pct:.0f}% YoY\",\n",
    "        xy=(xi, totals_v3[xi]),\n",
    "        xytext=(xi + 0.35, totals_v3[xi] + max(totals_v3) * 0.1),\n",
    "        fontsize=7.5, color=\"#8b949e\",\n",
    "        arrowprops=dict(arrowstyle=\"->\", color=\"#484f58\", lw=0.8),\n",
    "        ha=\"left\", va=\"bottom\", fontfamily=\"monospace\"\n",
    "    )\n",
    "\n",
    "ax_main.set_facecolor(\"#161b22\")\n",
    "ax_main.spines[:].set_edgecolor(\"#30363d\")\n",
    "ax_main.set_ylabel(\"Number of Incidents\", labelpad=8)\n",
    "ax_main.set_xticks([])\n",
    "ax_main.set_xlim(-0.5, len(YEARS) - 0.5)\n",
    "ax_main.set_title(\n",
    "    f\"Incident Surge vs. Harm Severity  Â·  {VIZ_YEAR_START}â€“{VIZ_YEAR_END}\\n\"\n",
    "    \"Bars = total incidents (Unintentional + Intentional)  |  Dashed line = confirmed harm rate  |  Bubbles = harm event count\",\n",
    "    fontsize=12, pad=12\n",
    ")\n",
    "ax_main.grid(axis=\"y\", alpha=0.25, zorder=0)\n",
    "ax_main.set_axisbelow(True)\n",
    "\n",
    "h1, l1 = ax_main.get_legend_handles_labels()\n",
    "h2, l2 = ax_r.get_legend_handles_labels()\n",
    "ax_main.legend(h1 + h2, l1 + l2, loc=\"upper left\", framealpha=0.9, ncol=2)\n",
    "\n",
    "# Injury sub-panel\n",
    "inj_colors = [DANGER if v > inj_cap * 0.5 else WARN if v > 50 else ACCENT\n",
    "              for v in injuries_v3]\n",
    "ax_inj.bar(x, injuries_v3, width=w, color=inj_colors, alpha=0.8, zorder=2)\n",
    "for xi, (yr, v) in enumerate(zip(YEARS, injuries_v3)):\n",
    "    actual = inj_raw[xi]\n",
    "    label  = f\"{actual/1000:.0f}k\" if actual >= 1000 else str(int(actual))\n",
    "    if actual > 0:\n",
    "        ax_inj.text(xi, v + 15, label, ha=\"center\", fontsize=7,\n",
    "                    color=\"#c9d1d9\", fontfamily=\"monospace\")\n",
    "\n",
    "ax_inj.set_facecolor(\"#161b22\")\n",
    "ax_inj.spines[:].set_edgecolor(\"#30363d\")\n",
    "ax_inj.set_ylabel(f\"Injuries\\n(cap {inj_cap/1000:.1f}k)\", fontsize=8, labelpad=4)\n",
    "ax_inj.set_xticks(x)\n",
    "ax_inj.set_xticklabels(YEARS, fontsize=9)\n",
    "ax_inj.grid(axis=\"y\", alpha=0.25, zorder=0)\n",
    "ax_inj.set_axisbelow(True)\n",
    "ax_inj.set_xlim(-0.5, len(YEARS) - 0.5)\n",
    "\n",
    "if SAVE_CHARTS:\n",
    "    out_path = str(Path(UPLOADED_PATH).parent / \"viz3_surge_vs_harm.png\")\n",
    "    plt.savefig(out_path, dpi=CHART_DPI, bbox_inches=\"tight\",\n",
    "                facecolor=\"#0d1117\", edgecolor=\"none\")\n",
    "    print(f\"ğŸ’¾  Saved: {out_path}\")\n",
    "\n",
    "plt.show()\n",
    "\n",
    "# â”€â”€ Dynamic insights â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€\n",
    "yr_max_vol  = YEARS[totals_v3.index(max(totals_v3))]\n",
    "yr_max_harm = YEARS[harms_v3.index(max(harms_v3))] if max(harms_v3) > 0 else \"N/A\"\n",
    "yr_first    = YEARS[0];  yr_last = YEARS[-1]\n",
    "growth_mult = totals_v3[-1] / totals_v3[0] if totals_v3[0] > 0 else 0\n",
    "avg_harm_rate_early = sum(harm_rate[:3]) / 3 if len(harm_rate) >= 3 else 0\n",
    "avg_harm_rate_late  = sum(harm_rate[-3:]) / 3 if len(harm_rate) >= 3 else 0\n",
    "\n",
    "print(\"\\nğŸ“Œ  KEY INSIGHTS â€” computed from your data\")\n",
    "print(f\"    Incident volume {yr_first}â†’{yr_last}: {totals_v3[0]} â†’ {totals_v3[-1]}  \"\n",
    "      f\"({growth_mult:.1f}Ã— growth)\")\n",
    "print(f\"    Year with most incidents : {yr_max_vol}  ({max(totals_v3):,})\")\n",
    "print(f\"    Year with most confirmed harm events : {yr_max_harm}  ({max(harms_v3)})\")\n",
    "if avg_harm_rate_early > 0:\n",
    "    harm_trend = \"declining â†“\" if avg_harm_rate_late < avg_harm_rate_early else \"rising â†‘\"\n",
    "    print(f\"    Harm rate trend (early {yr_first}-{YEARS[2]} avg {avg_harm_rate_early:.1f}%  \"\n",
    "          f\"â†’  late {YEARS[-3]}-{yr_last} avg {avg_harm_rate_late:.1f}%) : {harm_trend}\")\n",
    "total_intent_all = sum(intents_v3)\n",
    "total_all        = sum(totals_v3)\n",
    "if total_all > 0:\n",
    "    print(f\"    Intentional incidents overall : {total_intent_all:,}  \"\n",
    "          f\"({total_intent_all/total_all*100:.1f}% of all incidents in this window)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "md_summary",
   "metadata": {},
   "source": [
    "---\n",
    "## ğŸ“ Summary & Downloads\n",
    "\n",
    "All 3 visualizations are complete. The charts have been:\n",
    "- **Displayed above** in the notebook output\n",
    "- **Saved as PNG files** alongside your uploaded Excel file (if `SAVE_CHARTS = True`)\n",
    "\n",
    "To download the saved PNGs in Google Colab, run the cell below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd_download",
   "metadata": {},
   "outputs": [],
   "source": [
    "# â•”â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•—\n",
    "# â•‘  ğŸ’¾  CELL 9 â€” DOWNLOAD SAVED CHARTS  (Google Colab only)                    â•‘\n",
    "# â•‘  Run this cell to download the PNG files to your computer.                  â•‘\n",
    "# â•šâ•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•\n",
    "\n",
    "chart_files = [\n",
    "    str(Path(UPLOADED_PATH).parent / f)\n",
    "    for f in [\"viz1_risk_heatmap.png\", \"viz2_sector_harm.png\", \"viz3_surge_vs_harm.png\"]\n",
    "]\n",
    "\n",
    "found = [f for f in chart_files if Path(f).exists()]\n",
    "\n",
    "if not found:\n",
    "    print(\"âš ï¸  No saved chart files found.\")\n",
    "    print(\"   Make sure SAVE_CHARTS = True in Cell 1 and re-run the visualization cells.\")\n",
    "elif IN_COLAB:\n",
    "    print(\"ğŸ“¥  Downloading charts to your computer...\")\n",
    "    for f in found:\n",
    "        colab_files.download(f)\n",
    "        print(f\"    âœ…  {Path(f).name}\")\n",
    "else:\n",
    "    print(\"ğŸ“  Charts saved locally:\")\n",
    "    for f in found:\n",
    "        print(f\"    âœ…  {Path(f).resolve()}\")"
   ]
  }
 ]
}
